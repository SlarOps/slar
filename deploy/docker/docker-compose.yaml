# version: "3.9"

services:
  ai:
    container_name: slar-ai
    platform: linux/amd64
    image: ghcr.io/slarops/slar-ai:latest
    expose:
      - "8002"
    ports:
      - "8002:8002"
    volumes:
      - claude_data:/root/.claude
      - ./volumes/config/dev.config.yaml:/app/config.yaml
    environment:
      - SLAR_CONFIG_PATH=/app/config.yaml
    restart: unless-stopped
    networks:
      - slar-network

  api:
    container_name: slar-api
    platform: linux/amd64
    image: ghcr.io/slarops/slar-api:latest
    expose:
      - "8080"
    ports:
      - "8080:8080"
    volumes:
      - ./volumes/config/dev.config.yaml:/app/config.yaml
    environment:
      - SLAR_CONFIG_PATH=/app/config.yaml
    restart: unless-stopped
    networks:
      - slar-network

  slack-worker:
    container_name: slar-slack-worker
    platform: linux/amd64
    image: ghcr.io/slarops/slar-slack-worker:latest
    volumes:
      - ./volumes/config/dev.config.yaml:/app/config.yaml
    restart: unless-stopped
    networks:
      - slar-network

  web:
    container_name: slar-web
    platform: linux/amd64
    image: ghcr.io/slarops/slar-web:latest
    expose:
      - "3000"
    ports:
      - "3000:3000"
    restart: unless-stopped
    networks:
      - slar-network

  kong:
    container_name: kong
    platform: linux/amd64
    image: kong:2.8.1
    ports:
      - "8000:8000/tcp"
    volumes:
      - ./volumes/api/kong.yaml:/home/kong/temp.yml:ro,z
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml
      KONG_DNS_ORDER: LAST,A,CNAME
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
    restart: unless-stopped
    networks:
      - slar-network
    entrypoint: bash -c 'eval "echo \"$$(cat ~/temp.yml)\"" > ~/kong.yml && /docker-entrypoint.sh kong docker-start'

networks:
  slar-network:
    driver: bridge

volumes:
  claude_data:
